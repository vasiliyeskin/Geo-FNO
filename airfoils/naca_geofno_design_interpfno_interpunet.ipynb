{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORovYSZb79l8TThn3Cir+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasiliyeskin/Geo-FNO/blob/veskin/airfoils/naca_geofno_design_interpfno_interpunet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Geo-FNO](https://github.com/zongyi-li/Geo-FNO) test on colab\n"
      ],
      "metadata": {
        "id": "iynOrXhKEIYt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKtba3FSD91Z"
      },
      "outputs": [],
      "source": [
        "!gdown https://drive.google.com/drive/folders/1YBuaoTdOSr_qzaow-G-iwvbUI7fiUzu8?usp=sharing -O /tmp/folder --folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vasiliyeskin/Geo-FNO.git"
      ],
      "metadata": {
        "id": "hvEV6tuXQa6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17feb5e8-d3fe-47b9-9bfa-49605609cb9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Geo-FNO'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 123 (delta 52), reused 70 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (123/123), 1.78 MiB | 30.34 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Geo-FNO/"
      ],
      "metadata": {
        "id": "UEqrWT64QfVp",
        "outputId": "83564cba-e8db-4fd0-dc34-a1e1b81e70fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Geo-FNO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout veskin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7M1_4EmqA60",
        "outputId": "c10a7354-205f-497f-f84c-d38de1c2e872"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'veskin' set up to track remote branch 'veskin' from 'origin'.\n",
            "Switched to a new branch 'veskin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "X5OMAsXlQ1up",
        "outputId": "6941f249-96fc-4796-b5ce-92983414e7e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adam.py  airfoils    FluidSolver  pipe\t      readme.md\n",
            "adan.py  elasticity  LICENSE\t  plasticity  utilities3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer\n",
        "from utilities3 import *\n",
        "from Adam import Adam\n",
        "from adan import Adan\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "urudIpUPQLNi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **I. Modify of the naca_geofno**"
      ],
      "metadata": {
        "id": "nn-O7MoMqTSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**fourier layer**"
      ],
      "metadata": {
        "id": "M1v2FZSrSYEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(\n",
        "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(\n",
        "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n",
        "                             device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        # Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x"
      ],
      "metadata": {
        "id": "YKyEQ9hISZho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
        "        input shape: (batchsize, x=s, y=s, c=3)\n",
        "        output: the solution \n",
        "        output shape: (batchsize, x=s, y=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 8  # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(4, self.width)  # input channel is 3: (a(x, y), x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        x = F.pad(x, [0, self.padding, 0, self.padding])\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = x[..., :-self.padding, :-self.padding]\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)"
      ],
      "metadata": {
        "id": "u54-h20jShp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **configs**"
      ],
      "metadata": {
        "id": "PUT-NE-FSrBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/tmp/folder/airfoil/naca/\"\n",
        "PATH = \"/tmp/folder/\"\n",
        "INPUT_X = PATH+'NACA_Cylinder_X.npy'\n",
        "INPUT_Y = PATH+'NACA_Cylinder_Y.npy'\n",
        "OUTPUT_Sigma = PATH+'NACA_Cylinder_Q.npy'\n",
        "\n",
        "ntrain = 1000\n",
        "ntest = 200\n",
        "\n",
        "batch_size = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "epochs = 501\n",
        "step_size = 100\n",
        "gamma = 0.5\n",
        "\n",
        "modes = 12\n",
        "width = 32\n",
        "\n",
        "r1 = 1\n",
        "r2 = 1\n",
        "s1 = int(((221 - 1) / r1) + 1)\n",
        "s2 = int(((51 - 1) / r2) + 1)\n",
        "\n",
        "clip = 0.37"
      ],
      "metadata": {
        "id": "QY-fEYHSStlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**load data and data normalization**"
      ],
      "metadata": {
        "id": "SEr__as6TBlG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputX = np.load(INPUT_X)\n",
        "inputX = torch.tensor(inputX, dtype=torch.float)\n",
        "inputY = np.load(INPUT_Y)\n",
        "inputY = torch.tensor(inputY, dtype=torch.float)\n",
        "input = torch.stack([inputX, inputY], dim=-1)\n",
        "\n",
        "output = np.load(OUTPUT_Sigma)[:, 4]\n",
        "output = torch.tensor(output, dtype=torch.float)\n",
        "print(input.shape, output.shape)\n",
        "\n",
        "x_train = input[:ntrain, ::r1, ::r2][:, :s1, :s2]\n",
        "y_train = output[:ntrain, ::r1, ::r2][:, :s1, :s2]\n",
        "x_test = input[ntrain:ntrain+ntest, ::r1, ::r2][:, :s1, :s2]\n",
        "y_test = output[ntrain:ntrain+ntest, ::r1, ::r2][:, :s1, :s2]\n",
        "x_train = x_train.reshape(ntrain, s1, s2, 2)\n",
        "x_test = x_test.reshape(ntest, s1, s2, 2)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), \n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), \n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "test_loader2 = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), \n",
        "                                           batch_size=1,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDg8dAohTBJ3",
        "outputId": "5ae24d7a-ba02-4684-c0d7-28de8e266735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2490, 221, 51, 2]) torch.Size([2490, 221, 51])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**training and evaluation**"
      ],
      "metadata": {
        "id": "2ncDOd9XTRfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FNO2d(modes*2, modes, width).cuda()\n",
        "print(count_params(model))\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# # new optimizer adan\n",
        "# max_grad_norm=0.0\n",
        "# weight_decay=0.02\n",
        "# opt_eps=1e-8\n",
        "# opt_betas=[0.98, 0.92, 0.99]\n",
        "# no_prox=False\n",
        "# optimizer = Adan(model.parameters(), \n",
        "#                  lr=learning_rate, \n",
        "#                  weight_decay=weight_decay, \n",
        "#                  betas=opt_betas, \n",
        "#                  eps = opt_eps, \n",
        "#                  max_grad_norm=max_grad_norm, \n",
        "#                  no_prox=no_prox)\n",
        "\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2 = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "\n",
        "        loss = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "        train_l2 += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_l2 = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "\n",
        "            out = model(x)\n",
        "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
        "\n",
        "    train_l2 /= ntrain\n",
        "    test_l2 /= ntest\n",
        "\n",
        "    t2 = default_timer()\n",
        "    print(ep, t2 - t1, train_l2, test_l2)\n",
        "\n",
        "    # plot\n",
        "    if ep%step_size==0:\n",
        "        # torch.save(model, '../model/naca_plain_model_'+str(ep))\n",
        "\n",
        "        ind = -1\n",
        "        X = x[ind, :, :, 0].squeeze().detach().cpu().numpy()\n",
        "        Y = x[ind, :, :, 1].squeeze().detach().cpu().numpy()\n",
        "        truth = y[ind].squeeze().detach().cpu().numpy()\n",
        "        pred = out[ind].squeeze().detach().cpu().numpy()\n",
        "        nx = 40//r1\n",
        "        ny = 20//r2\n",
        "        X_small = X[nx:-nx, :ny]\n",
        "        Y_small = Y[nx:-nx, :ny]\n",
        "        truth_small = truth[nx:-nx, :ny]\n",
        "        pred_small = pred[nx:-nx, :ny]\n",
        "\n",
        "        fig, ax = plt.subplots(nrows=3, ncols=2,  figsize=(16, 16))\n",
        "        ax[0,0].pcolormesh(X, Y, truth, shading='gouraud')\n",
        "        ax[1,0].pcolormesh(X, Y, pred, shading='gouraud')\n",
        "        ax[2,0].pcolormesh(X, Y, pred-truth, shading='gouraud')\n",
        "        ax[0,1].pcolormesh(X_small, Y_small, truth_small, shading='gouraud')\n",
        "        ax[1,1].pcolormesh(X_small, Y_small, pred_small, shading='gouraud')\n",
        "        ax[2,1].pcolormesh(X_small, Y_small, np.abs(pred_small-truth_small), shading='gouraud')\n",
        "        fig.show()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "43iWx2IeTUkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bq3QLuTQu8a-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **II. Modify of the naca_design**"
      ],
      "metadata": {
        "id": "5ta_BCWo_Tx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer\n",
        "from utilities3 import *\n",
        "from Adam import Adam\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "ChCXCzm8VzI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fourier layer"
      ],
      "metadata": {
        "id": "uJ83-m3I_fTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(\n",
        "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(\n",
        "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n",
        "                             device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        # Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
        "        input shape: (batchsize, x=s, y=s, c=3)\n",
        "        output: the solution \n",
        "        output shape: (batchsize, x=s, y=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 8  # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(4, self.width)  # input channel is 3: (a(x, y), x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "\n",
        "        x = F.pad(x, [0, self.padding, 0, self.padding])\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = x[..., :-self.padding, :-self.padding]\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)"
      ],
      "metadata": {
        "id": "kKuG8m3A_hTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## configs"
      ],
      "metadata": {
        "id": "ftqoEuHW_pnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/tmp/folder/airfoil/naca/\"\n",
        "# PATH = \"/tmp/folder/\"\n",
        "INPUT_X = PATH+'NACA_Cylinder_X.npy'\n",
        "INPUT_Y = PATH+'NACA_Cylinder_Y.npy'\n",
        "OUTPUT_Sigma = PATH+'NACA_Cylinder_Q.npy'\n",
        "\n",
        "ntrain = 1000\n",
        "ntest = 200\n",
        "batch_size = 20\n",
        "\n",
        "modes = 12\n",
        "width = 32\n",
        "\n",
        "r1 = 1\n",
        "r2 = 1\n",
        "s1 = int(((221 - 1) / r1) + 1)\n",
        "s2 = int(((51 - 1) / r2) + 1)"
      ],
      "metadata": {
        "id": "F-L4NP2C_rhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **load data and data normalization**"
      ],
      "metadata": {
        "id": "v-GwVYmR_5i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputX = np.load(INPUT_X)\n",
        "inputX = torch.tensor(inputX, dtype=torch.float)\n",
        "inputY = np.load(INPUT_Y)\n",
        "inputY = torch.tensor(inputY, dtype=torch.float)\n",
        "input = torch.stack([inputX, inputY], dim=-1)\n",
        "\n",
        "output = np.load(OUTPUT_Sigma)[:,3]\n",
        "output = torch.tensor(output, dtype=torch.float)\n",
        "print(input.shape, output.shape)\n",
        "\n",
        "x_train = input[:ntrain, ::r1, ::r2][:, :s1, :s2]\n",
        "y_train = output[:ntrain, ::r1, ::r2][:, :s1, :s2]\n",
        "\n",
        "x_test = input[ntrain:ntrain+ntest, ::r1, ::r2][:, :s1, :s2]\n",
        "y_test = output[ntrain:ntrain+ntest, ::r1, ::r2][:, :s1, :s2]\n",
        "\n",
        "x_train = x_train.reshape(ntrain, s1, s2, 2)\n",
        "x_test = x_test.reshape(ntest, s1, s2, 2)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "test_loader2 = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RmQZCZs_2Uw",
        "outputId": "5c19312b-42fb-4d7e-b7b4-50d68eb44c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2490, 221, 51, 2]) torch.Size([2490, 221, 51])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Design**"
      ],
      "metadata": {
        "id": "-kYAga__AIsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import optimize\n",
        "\n",
        "# symmetrical 4-digit NASA airfoil\n",
        "# the airfoil is in [0,1]\n",
        "def NACA_shape(x, digit=12):\n",
        "    return 5 * (digit / 100.0) * (\n",
        "                0.2969 * np.sqrt(x) - 0.1260 * x - 0.3516 * x ** 2 + 0.2843 * x ** 3 - 0.1036 * x ** 4)\n",
        "\n",
        "# generate mesh between a and b\n",
        "# dx0, dx0*r, dx0*r^2 ... dx0*r^{N-2}\n",
        "# b - a = dx0*(r^{N-1} - 1)/(r - 1)\n",
        "def GeoSpace(a, b, N, r=-1.0, dx0=-1.0):\n",
        "    xx = np.linspace(a, b, N)\n",
        "    if r > 1 or dx0 > 0:\n",
        "        if r > 1:\n",
        "            dx0 = (b - a) / ((r ** (N - 1) - 1) / (r - 1))\n",
        "            dx = dx0\n",
        "            for i in range(1, N - 1):\n",
        "                xx[i] = xx[i - 1] + dx\n",
        "                dx *= r\n",
        "        else:\n",
        "            # first use r=1.05 to generate half of the grids\n",
        "            # then compute r and generate another half of the grids\n",
        "            f = lambda r: (r - 1) * (b - a) - dx0 * (r ** (N - 1) - 1)\n",
        "            r = optimize.bisect(f, 1 + 1e-4, 1.5)\n",
        "\n",
        "            if r > 1.02:\n",
        "                r = min(r, 1.02)\n",
        "                dx = dx0\n",
        "                Nf = 3 * N // 4\n",
        "\n",
        "                for i in range(1, Nf):\n",
        "                    xx[i] = xx[i - 1] + dx\n",
        "                    dx *= r\n",
        "\n",
        "                a = xx[Nf - 1]\n",
        "                dx0 = dx\n",
        "\n",
        "                f = lambda r: (r - 1) * (b - a) - dx0 * (r ** (N - Nf) - 1)\n",
        "                r = optimize.bisect(f, 1 + 1e-4, 2.0)\n",
        "\n",
        "                for i in range(Nf, N - 1):\n",
        "                    xx[i] = xx[i - 1] + dx\n",
        "                    dx *= r\n",
        "            else:\n",
        "                dx = dx0\n",
        "                for i in range(1, N - 1):\n",
        "                    xx[i] = xx[i - 1] + dx\n",
        "                    dx *= r\n",
        "    return xx\n",
        "\n",
        "# Nx point on top skin\n",
        "def NACA_shape_mesh(Nx, method=\"stretching\", ratio=1.0):\n",
        "    if method == \"stretching\":\n",
        "        xx = np.zeros(Nx)\n",
        "        xx[1:] = GeoSpace(0, 1, Nx - 1, r=ratio ** (1 / (Nx - 3)))\n",
        "        xx[1] = xx[2] / 4.0\n",
        "    else:\n",
        "        print(\"method : \", method, \" is not recognized\")\n",
        "\n",
        "    xx = xx[::-1]\n",
        "    yy = np.hstack((NACA_shape(xx), -NACA_shape(xx[-2::-1])))\n",
        "    xx = np.hstack((xx, xx[-2::-1]))\n",
        "    return xx, yy\n",
        "\n",
        "\n",
        "# The undeformed box is\n",
        "# 0.5 - Lx/2  (8)        0.5 - Lx/6  (7)         0.5 + Lx/6  (6)          0.5 + Lx/2  (5)         (y = Ly/2)\n",
        "#\n",
        "# 0.5 - Lx/2  (1)        0.5 - Lx/6  (2)         0.5 + Lx/6  (3)          0.5 + Lx/2  (4)         (y = -Ly/2)\n",
        "#\n",
        "# basis function at node (i)   is Bᵢ   = Φᵢ(x) Ψ₁(y)    (1 ≤ i ≤ 4)\n",
        "# basis function at node (i+4) is Bᵢ₊₄ = Φᵢ(x) Ψ₂(y)    (1 ≤ i ≤ 4)\n",
        "#\n",
        "# The map is\n",
        "# (x, y) -> (x, y) + dᵢ Bᵢ(x,  y)\n",
        "#\n",
        "def NACA_sdesign(theta, x, y, Lx=1.5, Ly=0.2):\n",
        "    x1, x2, x3, x4 = 0.5 - Lx / 2, 0.5 - Lx / 6, 0.5 + Lx / 6, 0.5 + Lx / 2\n",
        "    y1, y2 = - Ly / 2, Ly / 2\n",
        "\n",
        "    phi1 = (x - x2) * (x - x3) * (x - x4) / ((x1 - x2) * (x1 - x3) * (x1 - x4))\n",
        "    phi2 = (x - x1) * (x - x3) * (x - x4) / ((x2 - x1) * (x2 - x3) * (x2 - x4))\n",
        "    phi3 = (x - x1) * (x - x2) * (x - x4) / ((x3 - x1) * (x3 - x2) * (x3 - x4))\n",
        "    phi4 = (x - x1) * (x - x2) * (x - x3) / ((x4 - x1) * (x4 - x2) * (x4 - x3))\n",
        "\n",
        "    psi1 = (y - y2) / (y1 - y2)\n",
        "    psi2 = (y - y1) / (y2 - y1)\n",
        "\n",
        "    B = torch.stack([phi2 * psi1, phi3 * psi1, phi4 * psi1, phi4 * psi2, phi3 * psi2, phi2 * psi2, phi1 * psi2], dim=0)\n",
        "    return x, y + torch.matmul(theta, B)\n",
        "\n",
        "def Cgrid2Cylinder(cnx1, cnx2, cny, Cgrid, Cylinder):\n",
        "    # Cgrid\n",
        "    nx1, nx2, ny = cnx1 + 1, cnx2 + 1, cny + 1\n",
        "\n",
        "    for j in range(cny + 1):\n",
        "        if j == 0:\n",
        "            Cylinder[0:cnx1 + cnx2, j] = Cgrid[0:cnx1 + cnx2]\n",
        "            Cylinder[cnx1 + cnx2:2 * nx1 + cnx2 - 1, j] = Cylinder[cnx1::-1, j]\n",
        "        else:\n",
        "            Cylinder[:, j] = Cgrid[(j - 1) * (2 * cnx1 + cnx2 + 1) + cnx1 + cnx2: (j - 1) * (\n",
        "                        2 * cnx1 + cnx2 + 1) + cnx1 + cnx2 + 1 + 2 * cnx1 + cnx2]\n",
        "\n",
        "def Cylinder2Cgrid(cnx1, cnx2, cny, Cylinder, Cgrid):\n",
        "    # Cylinder,\n",
        "    nx1, nx2, ny = cnx1 + 1, cnx2 + 1, cny + 1\n",
        "\n",
        "    for j in range(cny + 1):\n",
        "        if j == 0:\n",
        "            Cgrid[0:cnx1 + cnx2] = Cylinder[0:cnx1 + cnx2, j]\n",
        "        else:\n",
        "            Cgrid[(j - 1) * (2 * cnx1 + cnx2 + 1) + cnx1 + cnx2: (j - 1) * (\n",
        "                        2 * cnx1 + cnx2 + 1) + cnx1 + cnx2 + 1 + 2 * cnx1 + cnx2] = Cylinder[:, j]\n",
        "\n",
        "# c: number of cells\n",
        "# cnx1 C mesh behind trailing edge\n",
        "# cnx2 C mesh around airfoil\n",
        "# cny radial direction\n",
        "#\n",
        "# The airfoil is in [0,1]\n",
        "# R: radius of C mesh\n",
        "# L: the right end of the mesh\n",
        "# the bounding box of the mesh is [Rc-R, L], [-R, R]\n",
        "#\n",
        "# dy0, vertical mesh size\n",
        "cnx1=50\n",
        "dy0=2.0 / 120.0\n",
        "cnx2=120\n",
        "cny=50\n",
        "R=40\n",
        "Rc=1.0\n",
        "L=40\n",
        "cnx = 2 * cnx1 + cnx2\n",
        "nx1, nx2, ny = cnx1 + 1, cnx2 + 1, cny + 1  # points\n",
        "nnodes = (2 * nx1 + cnx2 - 1) * cny + (nx1 + cnx2 - 1)\n",
        "\n",
        "xx_airfoil, yy_airfoil = NACA_shape_mesh(cnx2 // 2 + 1, method=\"stretching\")\n",
        "xx_inner = GeoSpace(0, 1, nx1, dx0=np.sqrt((xx_airfoil[0] - xx_airfoil[1]) ** 2 + (yy_airfoil[0] - yy_airfoil[1]) ** 2) / (L - 1))\n",
        "xx_outer = GeoSpace(Rc, L, nx1)\n",
        "wy = GeoSpace(0, 1, ny, dx0=dy0 / R)\n",
        "\n",
        "xx_airfoil = torch.tensor(xx_airfoil, device='cuda', dtype=torch.float)\n",
        "yy_airfoil = torch.tensor(yy_airfoil, device='cuda', dtype=torch.float)\n",
        "xx_inner = torch.tensor(xx_inner, device='cuda', dtype=torch.float)\n",
        "xx_outer = torch.tensor(xx_outer, device='cuda', dtype=torch.float)\n",
        "wy = torch.tensor(wy, device='cuda', dtype=torch.float)\n",
        "\n",
        "def Theta2Mesh(theta, xx_airfoil=xx_airfoil, yy_airfoil=yy_airfoil, xx_inner=xx_inner, xx_outer=xx_outer):\n",
        "    # assert (len(theta) == 8 and theta[0] == 0.0)\n",
        "    assert (len(theta) == 7)\n",
        "\n",
        "    xx_airfoil, yy_airfoil = NACA_sdesign(theta, xx_airfoil, yy_airfoil)\n",
        "\n",
        "    xy_inner = torch.zeros((2 * nx1 + cnx2 - 1, 2), device='cuda', dtype=torch.float)\n",
        "    xy_outer = torch.zeros((2 * nx1 + cnx2 - 1, 2), device='cuda', dtype=torch.float)\n",
        "    # top flat\n",
        "    xy_inner[:nx1, 0] = torch.flip(xx_airfoil[0] * (1 - xx_inner) + L * xx_inner, dims=[0])\n",
        "    xy_inner[:nx1, 1] = torch.flip(yy_airfoil[0] * (1 - xx_inner), dims=[0])\n",
        "    xy_outer[:nx1, 0] = torch.flip(xx_outer, dims=[0])\n",
        "    xy_outer[:nx1, 1] = R\n",
        "\n",
        "    # airfoil\n",
        "    xy_inner[nx1 - 1:nx1 + cnx2, 0] = xx_airfoil\n",
        "    xy_inner[nx1 - 1:nx1 + cnx2, 1] = yy_airfoil\n",
        "\n",
        "    θθ = torch.linspace(np.pi / 2, 3 * np.pi / 2, nx2)\n",
        "    xy_outer[nx1 - 1:nx1 + cnx2, 0] = R * torch.cos(θθ) + Rc\n",
        "    xy_outer[nx1 - 1:nx1 + cnx2, 1] = R * torch.sin(θθ)\n",
        "    # bottom flat\n",
        "    xy_inner[nx1 + cnx2 - 1:2 * nx1 + cnx2 - 1, 0] = torch.flip(xy_inner[:nx1, 0], dims=[0])\n",
        "    xy_inner[nx1 + cnx2 - 1:2 * nx1 + cnx2 - 1, 1] = torch.flip(xy_inner[:nx1, 1], dims=[0])\n",
        "    xy_outer[nx1 + cnx2 - 1:2 * nx1 + cnx2 - 1, 0] = xx_outer\n",
        "    xy_outer[nx1 + cnx2 - 1:2 * nx1 + cnx2 - 1, 1] = -R\n",
        "\n",
        "    # Construct Cylinder grid\n",
        "    xx_Cylinder = torch.outer(xy_inner[:, 0], 1 - wy) + torch.outer(xy_outer[:, 0], wy)\n",
        "    yy_Cylinder = torch.outer(xy_inner[:, 1], 1 - wy) + torch.outer(xy_outer[:, 1], wy)\n",
        "    out = torch.stack([xx_Cylinder, yy_Cylinder], dim=-1).unsqueeze(0)\n",
        "    return out, xx_Cylinder, yy_Cylinder\n",
        "\n",
        "def compute_F(XC, YC, p, cnx1=50, cnx2=120, cny=50):\n",
        "    p = p.squeeze()\n",
        "    xx, yy, p = XC[cnx1:-cnx1, 0], YC[cnx1:-cnx1, 0], p[cnx1:-cnx1, 0]\n",
        "\n",
        "    drag = torch.matmul(yy[0:cnx2]-yy[1:cnx2+1], (p[0:cnx2] + p[1:cnx2+1])/2.0)\n",
        "    lift = torch.matmul(xx[1:cnx2+1]-xx[0:cnx2], (p[0:cnx2] + p[1:cnx2+1])/2.0)\n",
        "    return drag, lift"
      ],
      "metadata": {
        "id": "2Huytr5bAMRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **inverse optimization**"
      ],
      "metadata": {
        "id": "ViXcEFTEAqPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.load(PATH + '/model/naca_p_w32_500')\n",
        "# print(count_params(model))\n",
        "\n",
        "model = FNO2d(modes*2, modes, width).cuda()\n",
        "print(count_params(model))\n",
        "\n",
        "\n",
        "learning_rate = 0.00001\n",
        "epochs = 5001\n",
        "step_size = 1000\n",
        "gamma = 0.5\n",
        "theta = torch.zeros(7, dtype=torch.float, requires_grad=True, device=\"cuda\")\n",
        "optimizer = Adam([theta], lr=learning_rate)\n",
        "\n",
        "# # new optimizer adan\n",
        "# max_grad_norm=0.0\n",
        "# weight_decay=0.02\n",
        "# opt_eps=1e-8\n",
        "# opt_betas=[0.98, 0.92, 0.99]\n",
        "# no_prox=False\n",
        "# optimizer = Adan(model.parameters(), \n",
        "#                  lr=learning_rate, \n",
        "#                  weight_decay=weight_decay, \n",
        "#                  betas=opt_betas, \n",
        "#                  eps = opt_eps, \n",
        "#                  max_grad_norm=max_grad_norm, \n",
        "#                  no_prox=no_prox)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "\n",
        "    x, XC, YC = Theta2Mesh(theta)\n",
        "    out = model(x)\n",
        "    drag, lift = compute_F(XC, YC, out)\n",
        "    loss = ((drag/lift) ** 2)\n",
        "    reg = torch.norm(theta)\n",
        "    loss_sum = loss + 1*reg\n",
        "    loss_sum.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    t2 = default_timer()\n",
        "    print(f'Epoch No. {ep}, epoch duration = {t2 - t1}, {drag.item()}, {lift.item()}, {reg.item()}, {loss.item()}')\n",
        "\n",
        "    if ep%step_size==0:\n",
        "        print(theta.detach().cpu().numpy())\n",
        "        ind = -1\n",
        "        X = x[ind, :, :, 0].squeeze().detach().cpu().numpy()\n",
        "        Y = x[ind, :, :, 1].squeeze().detach().cpu().numpy()\n",
        "        pred = out[ind].squeeze().detach().cpu().numpy()\n",
        "        nx = 40//r1\n",
        "        ny = 20//r2\n",
        "        X_small = X[nx:-nx, :ny]\n",
        "        Y_small = Y[nx:-nx, :ny]\n",
        "        pred_small = pred[nx:-nx, :ny]\n",
        "        fig, ax = plt.subplots(ncols=2,  figsize=(16, 8))\n",
        "        ax[0].pcolormesh(X, Y, pred, shading='gouraud')\n",
        "        ax[1].pcolormesh(X_small, Y_small, pred_small, shading='gouraud')\n",
        "        fig.show()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "77oGpwCUArqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **III. naca_interp_fno**"
      ],
      "metadata": {
        "id": "ZXV3kxLpE2P8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from timeit import default_timer\n",
        "from utilities3 import *\n",
        "from Adam import Adam\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "EYRb6V7rC0bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **fourier layer**"
      ],
      "metadata": {
        "id": "FijxbmuyFLl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpectralConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
        "        super(SpectralConv2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1  # Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "        self.modes2 = modes2\n",
        "\n",
        "        self.scale = (1 / (in_channels * out_channels))\n",
        "        self.weights1 = nn.Parameter(\n",
        "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "        self.weights2 = nn.Parameter(\n",
        "            self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
        "\n",
        "    # Complex multiplication\n",
        "    def compl_mul2d(self, input, weights):\n",
        "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
        "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        # Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.fft.rfft2(x)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-2), x.size(-1) // 2 + 1, dtype=torch.cfloat,\n",
        "                             device=x.device)\n",
        "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
        "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
        "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
        "\n",
        "        # Return to physical space\n",
        "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
        "        return x\n",
        "\n",
        "\n",
        "class FNO2d(nn.Module):\n",
        "    def __init__(self, modes1, modes2, width):\n",
        "        super(FNO2d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
        "        input shape: (batchsize, x=s, y=s, c=3)\n",
        "        output: the solution \n",
        "        output shape: (batchsize, x=s, y=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes1\n",
        "        self.modes2 = modes2\n",
        "        self.width = width\n",
        "        self.padding = 9  # pad the domain if input is non-periodic\n",
        "        self.fc0 = nn.Linear(3, self.width)  # input channel is 3: (a(x, y), x, y)\n",
        "\n",
        "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
        "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        x = F.pad(x, [0, self.padding, 0, self.padding])\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.gelu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = x[..., :-self.padding, :-self.padding]\n",
        "        x = x.permute(0, 2, 3, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)"
      ],
      "metadata": {
        "id": "BL1dZJfdFJHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **configs**"
      ],
      "metadata": {
        "id": "Zt_M0ce-FSHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/tmp/folder/airfoil/naca_interp/\"\n",
        "X_PATH = PATH + 'NACA_X_interp.npy'\n",
        "Y_PATH = PATH + 'NACA_Y_interp.npy'\n",
        "INPUT_PATH = PATH + 'NACA_mask_interp.npy'\n",
        "OUTPUT_PATH = PATH + 'NACA_Q_interp.npy'\n",
        "Ntotal = 2000\n",
        "ntrain = 1000\n",
        "ntest = 200\n",
        "\n",
        "batch_size = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "epochs = 501\n",
        "step_size = 100\n",
        "gamma = 0.5\n",
        "\n",
        "modes = 12\n",
        "width = 32\n",
        "\n",
        "r = 1\n",
        "h = int(((101 - 1) / r) + 1)\n",
        "s = h"
      ],
      "metadata": {
        "id": "lLJcoUGHFQ26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **load data and data normalization**"
      ],
      "metadata": {
        "id": "s38vwcm-FmwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.load(INPUT_PATH)\n",
        "input = torch.tensor(input, dtype=torch.float)\n",
        "output = np.load(OUTPUT_PATH)\n",
        "output = torch.tensor(output, dtype=torch.float)\n",
        "\n",
        "x_train = input[:Ntotal][:ntrain, ::r, ::r][:, :s, :s]\n",
        "y_train = output[:Ntotal][:ntrain, ::r, ::r][:, :s, :s]\n",
        "x_test = input[:Ntotal][-ntest:, ::r, ::r][:, :s, :s]\n",
        "y_test = output[:Ntotal][-ntest:, ::r, ::r][:, :s, :s]\n",
        "x_train = x_train.reshape(ntrain, s, s, 1)\n",
        "x_test = x_test.reshape(ntest, s, s, 1)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "XX = np.load(X_PATH)[-1]\n",
        "YY = np.load(Y_PATH)[-1]"
      ],
      "metadata": {
        "id": "XXHVi8koFUtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **training and evaluation**"
      ],
      "metadata": {
        "id": "jaGcKIacF2qK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = FNO2d(modes, modes, width).cuda()\n",
        "print(count_params(model))\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2 = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        mask = x.clone()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        out = out*mask\n",
        "\n",
        "        loss = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_l2 += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_l2 = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            mask = x.clone()\n",
        "\n",
        "            out = model(x)\n",
        "            out2 = out * mask\n",
        "\n",
        "            test_l2 += myloss(out2.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
        "\n",
        "    train_l2 /= ntrain\n",
        "    test_l2 /= ntest\n",
        "\n",
        "    t2 = default_timer()\n",
        "    print(f'Epoch No. {ep}, epoch duration = {t2 - t1}, L2_train = {train_l2}, L2_test={test_l2}')\n",
        "\n",
        "    if ep%step_size==0:\n",
        "        # torch.save(model, '../model/naca_interp_' + str(ep))\n",
        "        X = XX\n",
        "        Y = YY\n",
        "        truth = y[-1].squeeze().detach().cpu().numpy()\n",
        "        pred = out2[-1].squeeze().detach().cpu().numpy()\n",
        "\n",
        "        fig, ax = plt.subplots(nrows=3, figsize=(9, 16))\n",
        "        ax[0].pcolormesh(X, Y, truth, shading='gouraud')\n",
        "        ax[1].pcolormesh(X, Y, pred, shading='gouraud')\n",
        "        ax[2].pcolormesh(X, Y, pred-truth, shading='gouraud')\n",
        "        fig.show()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "arwru5leFqZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IV. naca_interp_unet**"
      ],
      "metadata": {
        "id": "-i6Mne3-GV8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from timeit import default_timer\n",
        "from utilities3 import *\n",
        "from Adam import Adam\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "K-maVSp8GMF5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **UNet**\n",
        " UNET model: https://github.com/milesial/Pytorch-UNet"
      ],
      "metadata": {
        "id": "iX-rRHwQGfBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = nn.Linear(n_channels, 32)\n",
        "        self.down1 = Down(32, 64)\n",
        "        self.down2 = Down(64, 128)\n",
        "        self.down3 = Down(128, 256)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(256, 512 // factor)\n",
        "        self.up1 = Up(512, 256 // factor, bilinear)\n",
        "        self.up2 = Up(256, 128 // factor, bilinear)\n",
        "        self.up3 = Up(128, 64 // factor, bilinear)\n",
        "        self.up4 = Up(64, 32, bilinear)\n",
        "        self.outc = nn.Linear(32, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        grid = self.get_grid(x.shape, x.device)\n",
        "        x = torch.cat((x, grid), dim=-1)\n",
        "        x1 = self.inc(x).permute(0,3,1,2)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = x.permute(0,2,3,1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "    def get_grid(self, shape, device):\n",
        "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
        "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
        "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
        "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
        "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
        "        return torch.cat((gridx, gridy), dim=-1).to(device)"
      ],
      "metadata": {
        "id": "ARW34uTvGdcm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **configs**"
      ],
      "metadata": {
        "id": "Vbxggp2mGr4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/tmp/folder/airfoil/naca_interp/\"\n",
        "INPUT_PATH  = PATH+'NACA_mask_interp.npy'\n",
        "OUTPUT_PATH  = PATH+'NACA_Q_interp.npy'\n",
        "Ntotal = 2000\n",
        "ntrain = 1000\n",
        "ntest = 200\n",
        "\n",
        "batch_size = 20\n",
        "learning_rate = 0.001\n",
        "\n",
        "epochs = 501\n",
        "step_size = 100\n",
        "gamma = 0.5\n",
        "\n",
        "modes = 12\n",
        "width = 32\n",
        "\n",
        "r = 1\n",
        "h = int(((101 - 1) / r) + 1)\n",
        "s = h"
      ],
      "metadata": {
        "id": "sfuhDwnaGoU1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **load data and data normalization**"
      ],
      "metadata": {
        "id": "Jh74-5xXHA-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.load(INPUT_PATH)\n",
        "input = torch.tensor(input, dtype=torch.float)\n",
        "output = np.load(OUTPUT_PATH)\n",
        "output = torch.tensor(output, dtype=torch.float)\n",
        "\n",
        "x_train = input[:Ntotal][:ntrain, ::r, ::r][:, :s, :s]\n",
        "y_train = output[:Ntotal][:ntrain, ::r, ::r][:, :s, :s]\n",
        "x_test = input[:Ntotal][-ntest:, ::r, ::r][:, :s, :s]\n",
        "y_test = output[:Ntotal][-ntest:, ::r, ::r][:, :s, :s]\n",
        "x_train = x_train.reshape(ntrain, s, s, 1)\n",
        "x_test = x_test.reshape(ntest, s, s, 1)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "GOzZ5gnUHCOv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **training and evaluation**"
      ],
      "metadata": {
        "id": "hz8S5LOGHHEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet().cuda()\n",
        "print(count_params(model))\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "myloss = LpLoss(size_average=False)\n",
        "\n",
        "for ep in range(epochs):\n",
        "    model.train()\n",
        "    t1 = default_timer()\n",
        "    train_l2 = 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        mask = x.clone()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        out = out*mask\n",
        "\n",
        "        loss = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        train_l2 += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_l2 = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "            mask = x.clone()\n",
        "\n",
        "            out = model(x)\n",
        "            out2 = out * mask\n",
        "\n",
        "            test_l2 += myloss(out2.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
        "\n",
        "    train_l2 /= ntrain\n",
        "    test_l2 /= ntest\n",
        "\n",
        "    t2 = default_timer()\n",
        "    print(ep, t2 - t1, train_l2, test_l2)"
      ],
      "metadata": {
        "id": "5ZsRCCXaHGhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "83I1FqmDHLW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}